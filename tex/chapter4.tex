\chapter{Challenges of Deterministic Concurrency}
\label{cha:challenges}

% Describe the problem of arbitrary reading data from an object that is
% concurrently being changed. Describe the idea of threshold reads and how it
% can be utilized to get determinism.

% TODO describe problems inherent with concurrent determinism
% TODO problems inherent in reactive async
% TODO problem inherent with freeze in LVish

% problems of reactive async includes:
% access to shared state is permitted within callbacks
% even then semantics of callback thread spawning is flawed

% Should we do these in the challenges? Prolly yes.
% TODO explain the problem of callback spawning
% TODO explain the problem of shared state

As noted in the introduction, achieving a high level of parallelization and
ensuring determinism is a difficult task. The inherent non-determinism of
concurrent operations leaves the programmer with a hard task, i.e. to consider
all paths of execution and making sure that they all lead to the same result.

Systems like Reactive Async and LVish both have the ambition of moving this
burden off the programmer and onto the programming model and type system. Both
however have problems. In this chapter we describe these problems in an informal
way. As a running example we will use the lattice of integers $(\integers,
\leq)$ with a bottom value of $-\infty$.

\section{Problems of Reactive Async}%
\label{sec:problems_of_reactive_async}

Reactive Async has two main problems. To highlight these we use a similar
example as the one in Figure~\ref{fig:ra_example}. Figure~\ref{fig:ra_example2}
describes a dependency graph which is a little more complex.

\begin{figure}
  \centering
  \begin{tikzpicture}
    \node[circle,draw] (c1) at (0, 1) {$c_1$};
    \node[circle,draw] (c2) at (0,-1) {$c_2$};
    \node[circle,draw] (c3) at (2, 0) {$c_3$};
    \node[circle,draw] (c4) at (4, 0) {$c_4$};
    \draw[-{Latex[length=0.3cm]}] (c1) -- node[above] {$f_1$} (c3);
    \draw[-{Latex[length=0.3cm]}] (c2) -- node[above] {$f_2$} (c3);
    \draw[-{Latex[length=0.3cm]}] (c3) -- node[above] {$f_3$} (c4);
  \end{tikzpicture}
  \caption{Reactive Async dependency graph.}
  \label{fig:ra_example2}
\end{figure}

\subsection{Sharing State}%
\label{sub:sharing_state}

The first problem of Reactive Async is that it is not prohibited for callbacks
to share mutable state. To exemplify this let $f_1$ and $f_2$ be as in
Figure~\ref{fig:ra_fun_shared_state}. This is written with Scala function syntax
and could be seen as a simplified version of Reactive Async. Say both are
scheduled to run and that the initial value of \ilc{Global.someInt} is $0$.
Also, let the initial cell value of all cells be $0$.  

Remember that, in Reactive Async the return value of a dependency function will
be used to update the dependent cell with through a put operation. Then it
should be clear that depending on the order in which $f_1$ and $f_2$ executes
$c_3$ will have a different final cell value. This is due to that the callbacks
share mutable state through the \ilc{Global} object.

This problem can be remedied with the help of the OCAP model. By ensuring that
callbacks threads are isolated in the reference graph we ensure that they do not
share any state.

\begin{figure}
  \begin{subfigure}[b]{0.5\textwidth}
    \begin{lstlisting}
(l) => {
  Global.someInt = 1
  0
}
    \end{lstlisting}
    \caption{Code of $f_1$.}
  \end{subfigure}
  ~
  \begin{subfigure}[b]{0.5\textwidth}
    \begin{lstlisting}
(l) => {
  if (Global.someInt == 1)
    1
  else 0
}
    \end{lstlisting}
    \caption{Code of $f_2$.}
  \end{subfigure}
  \caption{Two callback functions sharing state.}
  \label{fig:ra_fun_shared_state}
\end{figure}


\subsection{Callback Spawning Semantics}%
\label{sub:callback_spawning_semantics}

Remedying the above problem does not however, yield a deterministic system.
There is a flaw inherent in how Reactive Async decides to spawn a callback
thread. A thread is only spawned when a cell value actually changes, which means
that all put operations does not necessarily spawn a callback. To see that this
is a problem, let $f_1$, $f_2$ and $f_3$ be as in
Figure~\ref{fig:ra_fun_callback_spawn} and \ref{fig:ra_fun_callback_spawn}. Let
all cells have an initial value of $0$, and let both $f_1$ and $f_2$ be
scheduled to run.

Say $f_1$ runs before $f_2$. The result will be a put of $2$ to cell $c_3$.
Since $2 \sqcup 0 = 2$, the cell value of $c_3$ will be changed to $2$. Thus it
will spawn the callback $f_3(2)$. This callback will result in a put of $1$ to
$c_4$, i.e., $c_4$ will have its cell value updated to $1$. Running $f_2$ now
results in the value of $c_3$ being updated to $3$ which will spawn the callback
$f_3(3)$. The resulting put of $0$ to $c_4$ will not update $c_4$ since $0 \leq
1$. The final value of $c_4$ will in this case be $1$.

Now let $f_2$ execute before $f_3$. This results in a put of $3$ to $c_3$, which
results in $c_3$ being updated to $3$. The callback $f_3(3)$ will be spawned and
result in a put of $0$ to $c_4$. Since $0 \sqcup 0 = 0$ this will not change the
value of $c_4$. Now, if $f_1$ executes, it will result in a put of $2$ to $c_3$.
Since the cell value of $c_3$ is already $3$ and $2 \sqcup 3 = 3$, this will not
result in an update of $c_3$. Thus the callback $f_3(2)$ is never spawned. The
final cell value of $c_4$ for this execution order is $0$, clearly different
from before.
\begin{figure}
  \begin{minipage}{0.5\textwidth}
    \begin{subfigure}[b]{\linewidth}
      \begin{lstlisting}
(l) => 2
      \end{lstlisting}
      \caption{Code of $f_1$.}
    \end{subfigure}
    
    \begin{subfigure}[b]{\linewidth}
      \begin{lstlisting}
(l) => 3
      \end{lstlisting}
      \caption{Code of $f_2$.}
    \end{subfigure}
  \end{minipage}
  ~
  \begin{minipage}{0.5\textwidth}
    \begin{subfigure}[b]{\linewidth}
      \begin{lstlisting}
(l) => {
  if (l == 2)
    1
  else 0
}
      \end{lstlisting}
      \caption{Code of $f_3$.}
    \end{subfigure}
  \end{minipage}
  \caption{Trivial callback functions breaking determinism using callback spawning semantics.}
  \label{fig:ra_fun_callback_spawn}
\end{figure}

The problem of callback spawning can be remedied with the use of the threshold
sets of LVish. Instead of only spawning a callback thead when a cell value
changes, a callback will be spawned for each lattice value passed in the
specified threshold set.

% INTRO
% As noted in the introduction, a 
% there are problems inherent in both reactive async and LVish. 

% TODO describe the reactive async problems first

\section{LVish Freezing Problem}%
\label{sec:a_problem_of_lvish}

As hinted in the end of Section~\ref{sec:lvars}, the proof of quasi-determinism
of LVish is flawed. While this leaves the quasi-determinism of LVish an open
problem this is not really interesting. This is due to the fact that by adding a
simple if-statement to the language, we can easily construct a counterexample.

The core language of LVish is very minimal with a very implicit way to implement
threads. We will therefore resort to writing the counterexample in a language
more akin to the system of Reactive Async, with the modification of having all
put operations being explicit in code and requiring all callbacks to have an
associated threshold set, similar to LVish. It can easily be translated into a
language and semantics of LVish (with the extension of an if-statement).

Say we have two cells $c_1$ and $c_2$ and two callbacks $f_1$ and $f_2$. Let the
lattice be $(\integers, \leq)$, let the initial cell values of both cells be 
$0$ and let both associated freeze bits be $\LVarsFalse$. The
callbacks are registered to some auxilliary cell $c$. 

\begin{table}
  \centering
  \begin{tabular}{c|c|c}
    Callback & Cell & Threshold Set \\
    \hline
    $f_1$ & $c$ & $\left\{ 0 \right\}$ \\
    $f_2$ & $c$ & $\left\{ 0 \right\}$ \\
  \end{tabular}
  \caption{Cell registration and threshold sets for $f_1$ and $f_2$.}
  \label{tab:cellreg}
\end{table}

The callback thread spawning semantics are as follows. If the value of a cell $c$
with a registerered callback $f$ passes $l \in T$, $T$ being the threshold set
assiciated with $f$, the callback $f(l)$ will be spawned eventually. This is
equivalent with the semantics of LVish.

There are two main operations used in our callback definitions. The freeze
statement \ilc{frz(...)} takes one argument of cell type and freezes the cell
specified, i.e. sets its associated freeze bit to true. Furthermore it returns
the associated cell value. The put operation \ilc{put(...)} takes two arguments,
one of cell type and one lattice value. This updates the cell value with the
specified one using the join operation. If the freeze bit is true and the join
result is not the same as the current value, the put operation results in a step
to $\Error$. The return value of \ilc{put} is the cell reference itself. We can
see an example of both in Figure~\ref{fig:ex_cell_op}.

% TODO change update to change above in callback spawning semantics.
\begin{figure}
  \centering
  \begin{subfigure}[t]{0.4\textwidth}
    \begin{lstlisting}[numbers=none,mathescape=true]
x = put($c$, l)
    \end{lstlisting}
    \caption{Example put operation. We put the lattice value assigned to \ilc{l} into
    cell $c$.}
  \end{subfigure}
  \quad
  \begin{subfigure}[t]{0.4\textwidth}
    \begin{lstlisting}[numbers=none,mathescape=true]
x = frz($c$)
    \end{lstlisting}
    \caption{Example freeze operation. We freeze the cell $c$ and assigns its cell
    value in variable \ilc{x}}
  \end{subfigure}
  \caption{Example cell operations.}
  \label{fig:ex_cell_op}
\end{figure}

Now let $f_1$ and $f_2$ be as in Figure~\ref{fig:lvish_fun_breaking}.
Furthermore let both $f_1$ and $f_2$ be scheduled (due to some put of integer
value greater than $0$ to auxilliary cell $c$).

If $f_1$ executes before $f_2$ we end up with an execution as described by
Table~\ref{stab:f_1exec}. It is clear that we never step to $\Error$.
If $f_2$ executes before $f_1$ we can describe the execution with
Table~\ref{stab:f_2exec}. Clearly the results differ and are non-erroneous, a
non-quasi-deterministic result.

\begin{figure}
  \centering
  \begin{subfigure}[t]{0.4\textwidth}
    \begin{lstlisting}[mathescape=true]
(l) => {
  x = frz($c_1$)
  if ( x == 0 )
    put($c_2$, 1)
}
    \end{lstlisting}
    \caption{Callback code for $f_1$.}
  \end{subfigure}
  \quad
  \begin{subfigure}[t]{0.4\textwidth}
    \begin{lstlisting}[mathescape=true]
(l) => {
  x = frz($c_2$)
  if ( x == 0 )
    put($c_1$, 1)
}
    \end{lstlisting}
    \caption{Callback code for $f_2$.}
  \end{subfigure}
  \caption{Callback code to break determinism in LVish.}
  \label{fig:lvish_fun_breaking}
\end{figure}

\begin{table}
  \centering
  \begin{subtable}[t]{\textwidth}
    \centering
    \begin{tabular}{l|c|c|c|c}
      Execution point & $c_1$ cell val & $c_1$ frz bit & $c_2$ cell val & $c_2$
      frz bit \\
      \hline
      $f_1$ start & $0$ & \LVarsFalse & $0$ & \LVarsFalse \\
      $f_1$ termination & $0$ & \LVarsTrue & $1$ & \LVarsFalse \\
      $f_2$ start & $0$ & \LVarsTrue & $1$ & \LVarsFalse \\
      $f_2$ termination & $0$ & \LVarsTrue & $1$ & \LVarsTrue \\
    \end{tabular}
    \caption{$f_1$ executes before $f_2$.}
    \label{stab:f_1exec}
  \end{subtable}

  \vspace{0.5em}

  \begin{subtable}[t]{\textwidth}
    \centering
    \begin{tabular}{l|c|c|c|c}
      Execution point & $c_1$ cell val & $c_1$ frz bit & $c_2$ cell val & $c_2$
      frz bit \\
      \hline
      $f_2$ start & $0$ & \LVarsFalse & $0$ & \LVarsFalse \\
      $f_2$ termination & $1$ & \LVarsFalse & $0$ & \LVarsTrue \\
      $f_1$ start & $1$ & \LVarsFalse & $0$ & \LVarsTrue \\
      $f_1$ termination & $1$ & \LVarsTrue & $0$ & \LVarsTrue \\
    \end{tabular}
    \caption{$f_2$ executes before $f_1$.}
    \label{stab:f_2exec}
  \end{subtable}
  \caption{Two different execution paths contradicting LVish quasi-determinism.}
\end{table}

This shows that as soon as we introduce the if-statement, a basic part of any
programming language, we can easily break determinism. The problem is inherent
in the freeze statement. By freezing a variable we could attain information
about the value and freeze bit of another cell. In the example above, by
freezing cell $c_1$ ($c_2$) and inspecting its value we can attain information
about wether $c_2$ ($c_1$) has been frozen or not. By conditioning on this
information, we can skip a put operation that would otherwise lead to an error.

A simple solution to this problem is to simply remove the capability of freezing
a cell and this is the approach of the system presented in
chapter~\ref{cha:core_language}. It should be possible to add other
forms of freezing. This will be discussed in
chapter~\ref{cha:discussion_and_conclusion}.


% TODO then note that the LVish proof is flawed and even if you could find a
% proof it is not really interesting since if you introduce the if statement you
% could easily create counterexamples.
